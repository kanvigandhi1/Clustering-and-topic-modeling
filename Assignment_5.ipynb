{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 5: Clustering and Topic Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this assignment, you'll need to use the following dataset:\n",
    "- text_train.json: This file contains a list of documents. It's used for training models\n",
    "- text_test.json: This file contains a list of documents and their ground-truth labels. It's used for testing performance. This file is in the format shown below. Note, each document has a list of labels.\n",
    "You can load these files using json.load()\n",
    "\n",
    "|Text| Labels|\n",
    "|----|-------|\n",
    "|paraglider collides with hot air balloon ... | ['Disaster and Accident', 'Travel & Transportation']|\n",
    "|faa issues fire warning for lithium ... | ['Travel & Transportation'] |\n",
    "| .... |...|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1: K-Mean Clustering\n",
    "\n",
    "Define a function **cluster_kmean()** as follows: \n",
    "- Take two file name strings as inputs: $train\\_file$ is the file path of text_train.json, and $test\\_file$ is the file path of text_test.json\n",
    "- When generating tfidf weights, set the min_df to 5.\n",
    "- Use **KMeans** to cluster documents in $train\\_file$ into 3 clusters by **cosine similarity**  and **Euclidean distance** separately. Use sufficient iterations with different initial centroids to make sure clustering converge \n",
    "- Test the clustering model performance using $test\\_file$: \n",
    "  * Predict the cluster ID for each document in $test\\_file$.\n",
    "  * Let's only use the **first label** in the ground-truth label list of each test document, e.g. for the first document in the table above, you set the ground_truth label to \"Disaster and Accident\" only.\n",
    "  * Apply **majority vote** rule to dynamically map the predicted cluster IDs to the ground-truth labels in $test\\_file$. **Be sure not to hardcode the mapping** (e.g. write code like {0: \"Disaster and Accident\"}), because a  cluster may corrspond to a different topic in each run. (hint: if you use pandas, look for \"idxmax\" function) \n",
    "  * Calculate **precision/recall/f-score** for each label, compare the results from the two clustering models, and write your analysis in a pdf file \n",
    "- This function has no return. Print out confusion matrix, precision/recall/f-score. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2: LDA Clustering \n",
    "\n",
    "Q2.1. Define a function **cluster_lda()** as follows: \n",
    "1. Take two file name strings as inputs: $train\\_file$ is the file path of text_train.json, and $test\\_file$ is the file path of text_test.json\n",
    "2. Use **LDA** to train a topic model with documents in $train\\_file$ and the number of topics $K$ = 3. Keep min_df to 5 when generating tfidf weights, as in Q1.  \n",
    "3. Predict the topic distribution of each document in  $test\\_file$ and select the topic with highest probability. Similar to Q1, apply **majority vote rule** to map the topics to the labels and show the classification report. \n",
    "4. Return the array of topic proportion array\n",
    "\n",
    "Q2.2. Find similar documents\n",
    "- Define a function **find_similar_doc(doc_id, topic_mix)** to find **top 3 documents** that are the most similar to a selected one with index **doc_id** using the topic proportion array **topic_mix**. \n",
    "- You can calculate the cosine or Euclidean distance between two documents using the topic proportion array\n",
    "- Return the IDs of these similar documents.\n",
    "\n",
    "Q2.3. Provide a pdf document which contains: \n",
    "  - performance comparison between Q1 and Q2.1\n",
    "  - describe how you tune the model parameters, e.g. alpha, max_iter etc. in Q2.1.\n",
    "  - discuss how effective the method in Q2.2 is to find similar documents, compared with the tfidf weight cosine similarity we used before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 (Bonus): Biterm Topic Model (BTM)\n",
    "- There are many variants of LDA model. BTM is one designed for short text, while lDA in general expects documents with rich content.\n",
    "- Read this paper carefully http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.402.4032&rep=rep1&type=pdf and try to understand the design\n",
    "- Try the following experiments:\n",
    "    - Script a few thousand tweets by different hastags\n",
    "    - Run LDA and BTM respectively to discover topics among the collected tweets. BTM package can be found at https://pypi.org/project/biterm/\n",
    "    - Compare the performance of each model. If one model works better, explain why it works better,\n",
    "- Summarize your experiment in a pdf document.\n",
    "- Note there is no absolute right or wrong answer in this experiment. All you need is to give a try and understand how BTM works and differences between BTM and LDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note: Due to randomness involved in these alogorithms, you may get the same result as what I showed below. However, your result should be close after you tune parameters carefully.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.cluster import KMeansClusterer, cosine_distance\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import metrics\n",
    "import numpy as np\n",
    "import json, time\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MultiLabelBinarizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q1\n",
    "def cluster_kmean(train_file, test_file):\n",
    "    train=json.load(open(train_file,'r'))\n",
    "    test=json.load(open(test_file,'r'))\n",
    "    test_text, labels = zip(*test)\n",
    "    first_label=[item[0] for item in labels]\n",
    "    \n",
    "    tfidf_vect = TfidfVectorizer(stop_words=\"english\",\\\n",
    "                             min_df=5) \n",
    "    dtm_train= tfidf_vect.fit_transform(train)\n",
    "    dtm_test= tfidf_vect.transform(test_text)\n",
    "    \n",
    "    num_clusters=3\n",
    "\n",
    "    clusterer = KMeansClusterer(num_clusters, \\\n",
    "                            cosine_distance, \\\n",
    "                            repeats=20)\n",
    "\n",
    "    clusters = clusterer.cluster(dtm_train.toarray(), \\\n",
    "                             assign_clusters=True)\n",
    "    \n",
    "    predict = [clusterer.classify(v) for v in dtm_test.toarray()]\n",
    "    \n",
    "    df=pd.DataFrame(list(zip(first_label, predict)), \\\n",
    "                columns=['actual_class','cluster'])\n",
    " \n",
    "    confusion = pd.crosstab( index=df.cluster, columns=df.actual_class)\n",
    "    print(confusion)\n",
    "    \n",
    "    mapping = confusion.idxmax(axis=1)\n",
    "    for idx, t in enumerate(mapping):\n",
    "        print(\"Cluster {}: Topic {}\".format(idx, t))\n",
    "    \n",
    "    predicted_target=[mapping[i] for i in predict]\n",
    "\n",
    "    print(metrics.classification_report(first_label, predicted_target))\n",
    "    \n",
    "    ###Euclidean\n",
    "    \n",
    "    num_clusters=3\n",
    "\n",
    "    Euclidean_km = KMeans(n_clusters=num_clusters, n_init=20).fit(dtm_test)\n",
    "    \n",
    "\n",
    "    clusters = Euclidean_km.labels_.tolist()\n",
    "    \n",
    "    predicted2 = Euclidean_km.predict(dtm_test)\n",
    "\n",
    "    confusion_df2 = pd.DataFrame(list(zip(first_label, predicted2)), \\\n",
    "                columns=['actual_class','cluster'])\n",
    "    #confusion_df2.head()\n",
    "\n",
    "# generate crosstab between clusters and true labels\n",
    "    confusion_df3 = pd.crosstab( index=confusion_df2.cluster, columns=confusion_df2.actual_class)\n",
    "    \n",
    "    \n",
    "    mapping = confusion_df3.idxmax(axis=1)\n",
    "    for idx, t in enumerate(mapping):\n",
    "        print(\"Cluster {}: Topic {}\".format(idx, t))\n",
    "    \n",
    "    predicted_target=[mapping[i] for i in predicted2]\n",
    "\n",
    "    print(metrics.classification_report(first_label, predicted_target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual_class  Disaster and Accident  News and Economy  Travel & Transportation\n",
      "cluster                                                                       \n",
      "0                                87                 1                      132\n",
      "1                                83                 9                       36\n",
      "2                                40               196                       16\n",
      "Cluster 0: Topic Travel & Transportation\n",
      "Cluster 1: Topic Disaster and Accident\n",
      "Cluster 2: Topic News and Economy\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "  Disaster and Accident       0.65      0.40      0.49       210\n",
      "       News and Economy       0.78      0.95      0.86       206\n",
      "Travel & Transportation       0.60      0.72      0.65       184\n",
      "\n",
      "               accuracy                           0.69       600\n",
      "              macro avg       0.68      0.69      0.67       600\n",
      "           weighted avg       0.68      0.69      0.67       600\n",
      "\n",
      "Cluster 0: Topic Disaster and Accident\n",
      "Cluster 1: Topic News and Economy\n",
      "Cluster 2: Topic Travel & Transportation\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "  Disaster and Accident       0.94      0.16      0.27       210\n",
      "       News and Economy       0.86      0.53      0.65       206\n",
      "Travel & Transportation       0.40      0.95      0.56       184\n",
      "\n",
      "               accuracy                           0.53       600\n",
      "              macro avg       0.73      0.55      0.50       600\n",
      "           weighted avg       0.75      0.53      0.49       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    # Due to randomness, you won't get the exact result\n",
    "    # as shown here, but your result should be close\n",
    "    # if you tune the parameters carefully\n",
    "    \n",
    "    # Q1\n",
    "    cluster_kmean('train_text.json', \\\n",
    "                  'test_text.json')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Q2\n",
    "def cluster_lda(train_file, test_file):\n",
    "    train=json.load(open(train_file,'r'))\n",
    "    test=json.load(open(test_file,'r'))\n",
    "    test_text, labels=zip(*test)\n",
    "    first_label=[item[0] for item in labels]\n",
    "    \n",
    "    tfidf_vect = CountVectorizer(min_df=5, stop_words='english')\n",
    "    \n",
    "    dtm_train= tfidf_vect.fit_transform(train)\n",
    "    dtm_test= tfidf_vect.transform(test_text)\n",
    " \n",
    "    num_clusters=3\n",
    "\n",
    "    lda = LatentDirichletAllocation(n_components=num_clusters, learning_method='batch',\\\n",
    "                                max_iter=25,verbose=1, n_jobs=1,\n",
    "                                random_state=0).fit(dtm_train)\n",
    "    \n",
    "    topic_assign=lda.transform(dtm_test)\n",
    "    \n",
    "    predict=topic_assign.argmax(axis=1)\n",
    "    \n",
    "    df=pd.DataFrame(list(zip(first_label, predict)), \\\n",
    "                columns=['actual_class','cluster'])\n",
    "\n",
    "    confusion = pd.crosstab( index=df.cluster, \\\n",
    "                            columns=df.actual_class)\n",
    "    print(confusion.head())\n",
    "    mapping = confusion.idxmax(axis=1)\n",
    "    for idx, t in enumerate(mapping):\n",
    "        print(\"Cluster {}: Topic {}\".format(idx, t))\n",
    "    \n",
    "    predicted_target=[mapping[i] for i in predict]\n",
    "\n",
    "    print(metrics.classification_report(first_label, \\\n",
    "                                        predicted_target))\n",
    "\n",
    "    return topic_assign, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Q2\n",
      "iteration: 1 of max_iter: 25\n",
      "iteration: 2 of max_iter: 25\n",
      "iteration: 3 of max_iter: 25\n",
      "iteration: 4 of max_iter: 25\n",
      "iteration: 5 of max_iter: 25\n",
      "iteration: 6 of max_iter: 25\n",
      "iteration: 7 of max_iter: 25\n",
      "iteration: 8 of max_iter: 25\n",
      "iteration: 9 of max_iter: 25\n",
      "iteration: 10 of max_iter: 25\n",
      "iteration: 11 of max_iter: 25\n",
      "iteration: 12 of max_iter: 25\n",
      "iteration: 13 of max_iter: 25\n",
      "iteration: 14 of max_iter: 25\n",
      "iteration: 15 of max_iter: 25\n",
      "iteration: 16 of max_iter: 25\n",
      "iteration: 17 of max_iter: 25\n",
      "iteration: 18 of max_iter: 25\n",
      "iteration: 19 of max_iter: 25\n",
      "iteration: 20 of max_iter: 25\n",
      "iteration: 21 of max_iter: 25\n",
      "iteration: 22 of max_iter: 25\n",
      "iteration: 23 of max_iter: 25\n",
      "iteration: 24 of max_iter: 25\n",
      "iteration: 25 of max_iter: 25\n",
      "actual_class  Disaster and Accident  News and Economy  Travel & Transportation\n",
      "cluster                                                                       \n",
      "0                                30                18                      138\n",
      "1                                12               182                        8\n",
      "2                               168                 6                       38\n",
      "Cluster 0: Topic Travel & Transportation\n",
      "Cluster 1: Topic News and Economy\n",
      "Cluster 2: Topic Disaster and Accident\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "  Disaster and Accident       0.79      0.80      0.80       210\n",
      "       News and Economy       0.90      0.88      0.89       206\n",
      "Travel & Transportation       0.74      0.75      0.75       184\n",
      "\n",
      "               accuracy                           0.81       600\n",
      "              macro avg       0.81      0.81      0.81       600\n",
      "           weighted avg       0.81      0.81      0.81       600\n",
      "\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    # Due to randomness, you won't get the exact result\n",
    "    # as shown here, but your result should be close\n",
    "    # if you tune the parameters carefully\n",
    "    \n",
    "            \n",
    "    # Q2\n",
    "    print(\"\\nQ2\")\n",
    "    topic_assign =cluster_lda('train_text.json', \\\n",
    "        'test_text.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cluster_lda(train_file, test_file):\n",
    "    train=json.load(open(train_file,'r'))\n",
    "    test=json.load(open(test_file,'r'))\n",
    "    test_text, labels=zip(*test)\n",
    "    first_label=[item[0] for item in labels]\n",
    "    \n",
    "    tfidf_vect = CountVectorizer(min_df=5, stop_words='english')\n",
    "    \n",
    "    dtm_train= tfidf_vect.fit_transform(train)\n",
    "    dtm_test= tfidf_vect.transform(test_text)\n",
    " \n",
    "    num_clusters=3\n",
    "\n",
    "    lda = LatentDirichletAllocation(n_components=num_clusters, learning_method='batch',\\\n",
    "                                max_iter=25,verbose=1, n_jobs=1,\n",
    "                                random_state=0).fit(dtm_train)\n",
    "    \n",
    "    topic_assign=lda.transform(dtm_test)\n",
    "    \n",
    "    predict=topic_assign.argmax(axis=1)\n",
    "    \n",
    "    df=pd.DataFrame(list(zip(first_label, predict)), \\\n",
    "                columns=['actual_class','cluster'])\n",
    "\n",
    "    confusion = pd.crosstab( index=df.cluster, \\\n",
    "                            columns=df.actual_class)\n",
    "    print(confusion.head())\n",
    "    mapping = confusion.idxmax(axis=1)\n",
    "    for idx, t in enumerate(mapping):\n",
    "        print(\"Cluster {}: Topic {}\".format(idx, t))\n",
    "    \n",
    "    predicted_target=[mapping[i] for i in predict]\n",
    "\n",
    "    print(metrics.classification_report(first_label, \\\n",
    "                                        predicted_target))\n",
    "\n",
    "    return topic_assign, labels\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def find_similar_doc(doc_id,topic_assign):\n",
    "    \n",
    "    \n",
    "    docs_tokens={idx:tokenize(doc) \\\n",
    "             for idx,doc in enumerate(docs)}\n",
    "\n",
    "    # step 3. get document-term matrix\n",
    "    dtm=pd.DataFrame.from_dict(docs_tokens, orient=\"index\" )\n",
    "    dtm=dtm.fillna(0)\n",
    "    \n",
    "    # step 4. get normalized term frequency (tf) matrix        \n",
    "    tf=dtm.values\n",
    "    doc_len=tf.sum(axis=1)\n",
    "    print(doc_len)\n",
    "    tf=np.divide(tf.T, doc_len).T\n",
    "    \n",
    "    # step 5. get idf\n",
    "    df=np.where(tf>0,1,0)\n",
    "    #idf=np.log(np.divide(len(docs), \\\n",
    "    #    np.sum(df, axis=0)))+1\n",
    "\n",
    "    smoothed_idf=np.log(np.divide(len(docs)+1, np.sum(df, axis=0)+1))+1    \n",
    "    smoothed_tf_idf=tf*smoothed_idf\n",
    "    \n",
    "   \n",
    "    Simalarity =1-spatial.distance.cosine(topic_assign[10],topic_assign[i])\n",
    "    \n",
    "    # the best score is always at the diagnal. a doc is similar to itself with score =1\n",
    "    # return the second largest\n",
    "    top_sim_index=np.argsort(Simalarity[doc_id])[::-1][1]\n",
    "    \n",
    "    return  top_sim_index, Simalarity[doc_id,top_sim_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Q2\n",
    "def cluster_lda(train_file, test_file):\n",
    "    \n",
    "    topic_assign = None\n",
    "    \n",
    "    # add your code here\n",
    "    \n",
    "    return topic_assign\n",
    "\n",
    "def find_similar(doc_id, topic_assign):\n",
    "    \n",
    "    docs = None\n",
    "    \n",
    "    # add your code here\n",
    "    \n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1\n",
      "cosine\n",
      "actual_class  Disaster and Accident  News and Economy  Travel & Transportation\n",
      "cluster                                                                       \n",
      "0                                61                 2                      152\n",
      "1                               109                 7                       25\n",
      "2                                40               197                        7\n",
      "Cluster 0: Topic Travel & Transportation\n",
      "Cluster 1: Topic Disaster and Accident\n",
      "Cluster 2: Topic News and Economy\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "  Disaster and Accident       0.77      0.52      0.62       210\n",
      "       News and Economy       0.81      0.96      0.88       206\n",
      "Travel & Transportation       0.71      0.83      0.76       184\n",
      "\n",
      "              micro avg       0.76      0.76      0.76       600\n",
      "              macro avg       0.76      0.77      0.75       600\n",
      "           weighted avg       0.76      0.76      0.75       600\n",
      "\n",
      "L2\n",
      "actual_class  Disaster and Accident  News and Economy  Travel & Transportation\n",
      "cluster                                                                       \n",
      "0                               174                34                      174\n",
      "1                                31               166                       10\n",
      "2                                 5                 6                        0\n",
      "Cluster 0: Topic Disaster and Accident\n",
      "Cluster 1: Topic News and Economy\n",
      "Cluster 2: Topic News and Economy\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "  Disaster and Accident       0.46      0.83      0.59       210\n",
      "       News and Economy       0.79      0.83      0.81       206\n",
      "Travel & Transportation       0.00      0.00      0.00       184\n",
      "\n",
      "              micro avg       0.58      0.58      0.58       600\n",
      "              macro avg       0.41      0.55      0.47       600\n",
      "           weighted avg       0.43      0.58      0.48       600\n",
      "\n",
      "\n",
      "Q2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rliu/anaconda/envs/py36/lib/python3.6/site-packages/sklearn/metrics/classification.py:1143: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration: 1 of max_iter: 25\n",
      "iteration: 2 of max_iter: 25\n",
      "iteration: 3 of max_iter: 25\n",
      "iteration: 4 of max_iter: 25\n",
      "iteration: 5 of max_iter: 25, perplexity: 3494.8408\n",
      "iteration: 6 of max_iter: 25\n",
      "iteration: 7 of max_iter: 25\n",
      "iteration: 8 of max_iter: 25\n",
      "iteration: 9 of max_iter: 25\n",
      "iteration: 10 of max_iter: 25, perplexity: 3416.5917\n",
      "iteration: 11 of max_iter: 25\n",
      "iteration: 12 of max_iter: 25\n",
      "iteration: 13 of max_iter: 25\n",
      "iteration: 14 of max_iter: 25\n",
      "iteration: 15 of max_iter: 25, perplexity: 3382.7160\n",
      "iteration: 16 of max_iter: 25\n",
      "iteration: 17 of max_iter: 25\n",
      "iteration: 18 of max_iter: 25\n",
      "iteration: 19 of max_iter: 25\n",
      "iteration: 20 of max_iter: 25, perplexity: 3377.7126\n",
      "iteration: 21 of max_iter: 25\n",
      "iteration: 22 of max_iter: 25\n",
      "iteration: 23 of max_iter: 25\n",
      "iteration: 24 of max_iter: 25\n",
      "iteration: 25 of max_iter: 25, perplexity: 3375.9923\n",
      "actual_class  Disaster and Accident  News and Economy  Travel & Transportation\n",
      "cluster                                                                       \n",
      "0                                30                18                      138\n",
      "1                                12               182                        8\n",
      "2                               168                 6                       38\n",
      "Cluster 0: Topic Travel & Transportation\n",
      "Cluster 1: Topic News and Economy\n",
      "Cluster 2: Topic Disaster and Accident\n",
      "                         precision    recall  f1-score   support\n",
      "\n",
      "  Disaster and Accident       0.79      0.80      0.80       210\n",
      "       News and Economy       0.90      0.88      0.89       206\n",
      "Travel & Transportation       0.74      0.75      0.75       184\n",
      "\n",
      "              micro avg       0.81      0.81      0.81       600\n",
      "              macro avg       0.81      0.81      0.81       600\n",
      "           weighted avg       0.81      0.81      0.81       600\n",
      "\n",
      "cluster\n",
      "0    Travel & Transportation\n",
      "1           News and Economy\n",
      "2      Disaster and Accident\n",
      "dtype: object\n",
      "docs similar to 10: [337  38 222]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":  \n",
    "    \n",
    "    # Due to randomness, you won't get the exact result\n",
    "    # as shown here, but your result should be close\n",
    "    # if you tune the parameters carefully\n",
    "    \n",
    "    # Q1\n",
    "    print(\"Q1\")\n",
    "    cluster_kmean('../../dataset/train_text.json', \\\n",
    "                  '../../dataset/test_text.json')\n",
    "            \n",
    "    # Q2\n",
    "    print(\"\\nQ2\")\n",
    "    topic_assign =cluster_lda('../../dataset/train_text.json', \\\n",
    "        '../../dataset/test_text.json')\n",
    "    doc_ids = find_similar(10, topic_assign)\n",
    "    print (\"docs similar to {0}: {1}\".format(10, doc_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
